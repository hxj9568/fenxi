# Rossmann è¥ä¸šé¢å¼‚å¸¸å½’å› åˆ†æžæŠ¥å‘Š

## ðŸ“Œ ä¸€ã€é¡¹ç›®èƒŒæ™¯

- **é¡¹ç›®åœ°å€**ï¼š[Rossmann Store Sales - Kaggle](https://www.kaggle.com/c/rossmann-store-sales)
- **ç›®æ ‡**ï¼šä¸æ˜¯åšé¢„æµ‹ï¼Œè€Œæ˜¯é’ˆå¯¹ `train.csv` æ•°æ®ä¸­çš„æœ€è¿‘ä¸‰ä¸ªæœˆï¼ˆ2015å¹´7æœˆ~9æœˆï¼‰è¿›è¡Œ **è¥ä¸šé¢çŽ¯æ¯”å¼‚å¸¸å½’å› åˆ†æž**
- **æ–¹æ³•**ï¼šä½¿ç”¨ XGBoost æ¨¡åž‹ç»“åˆ SHAP åˆ†æžå·¥å…·ï¼Œè§£é‡Šå½±å“è¥ä¸šé¢å˜åŒ–çš„ä¸»è¦é©±åŠ¨å› ç´ åŠå…¶è´¡çŒ®åº¦

---

### 1. æ•°æ®å‡†å¤‡
- åˆå¹¶ `train.csv` å’Œ `store.csv`
- ä¿ç•™è¥ä¸šä¸­çš„æ•°æ®ï¼ˆOpen == 1 ä¸” Sales > 0ï¼‰
- é€‰å–æ—¶é—´èŒƒå›´ï¼š`2015-05-01` ~ `2015-07-30`


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# è¯»å–æ•°æ®
df_train = pd.read_csv('C:/Users/95680/Desktop/train.csv', low_memory=False, dtype={'StateHoliday': str})
df_store = pd.read_csv('C:/Users/95680/Desktop/store.csv')

# åˆå¹¶
df = pd.merge(df_train, df_store, on='Store')
df['Date'] = pd.to_datetime(df['Date'])

# åªä¿ç•™è¥ä¸šçŠ¶æ€ä¸ºå¼€çš„æ•°æ®
df = df[df['Open'] == 1]
df = df[df['Sales'] > 0]
```


```python
df['YearMonth'] = df['Date'].dt.to_period("M")
print(df['YearMonth'].value_counts().sort_index())
```

    YearMonth
    2013-01    28865
    2013-02    26682
    2013-03    27891
    2013-04    27878
    2013-05    26199
    2013-06    27939
    2013-07    30164
    2013-08    30023
    2013-09    27980
    2013-10    28990
    2013-11    28412
    2013-12    26901
    2014-01    28707
    2014-02    26791
    2014-03    29005
    2014-04    26917
    2014-05    28021
    2014-06    26209
    2014-07    25224
    2014-08    24388
    2014-09    24341
    2014-10    24301
    2014-11    22989
    2014-12    23492
    2015-01    28763
    2015-02    26766
    2015-03    29079
    2015-04    26931
    2015-05    25879
    2015-06    28423
    2015-07    30188
    Freq: M, Name: count, dtype: int64
    

å¯ä»¥çœ‹åˆ°ï¼Œæœ€è¿‘ä¸‰ä¸ªæœˆæœª2015-05åˆ°2015-07ï¼Œæˆ‘ä»¬é€‰æ‹©è¿™ä¸‰ä¸ªæœˆä½œä¸ºåˆ†æžçš„å¯¹è±¡

### 2. é”€å”®è¶‹åŠ¿ä¸ŽçŽ¯æ¯”å˜åŒ–
- æ¯æœˆè¥ä¸šé¢è¶‹åŠ¿å¯è§†åŒ–
- è®¡ç®—çŽ¯æ¯”å¢žé•¿ç™¾åˆ†æ¯”


```python
import matplotlib.pyplot as plt
plt.rcParams['font.family'] = 'SimHei'
plt.rcParams['axes.unicode_minus'] = False

# æŸ¥çœ‹æ—¶é—´èŒƒå›´
print("æ•°æ®æ—¶é—´èŒƒå›´ï¼š", df['Date'].min(), "åˆ°", df['Date'].max())

# é€‰å–æœ€è¿‘ä¸‰ä¸ªæœˆ
recent_df = df[(df['Date'] >= '2015-05-01') & (df['Date'] <= '2015-07-30')]
print("æœ€è¿‘ä¸‰ä¸ªæœˆæ•°æ®é‡ï¼š", recent_df.shape)

# æŒ‰æœˆé”€å”®é¢
monthly_sales = recent_df.groupby(recent_df['Date'].dt.to_period("M"))['Sales'].sum()
monthly_sales = monthly_sales.to_timestamp()
print("æ¯æœˆé”€å”®é¢ï¼š\n", monthly_sales)

# çŽ¯æ¯”å˜åŒ–
monthly_pct_change = monthly_sales.pct_change().fillna(0)

# å¯è§†åŒ–
fig, ax = plt.subplots(figsize=(10, 4))
monthly_sales.plot(marker='o', ax=ax, label='Monthly Sales')
for i in range(len(monthly_sales)):
    ax.text(monthly_sales.index[i], monthly_sales[i] + 20000, f"{monthly_pct_change[i]*100:.2f}%", ha='center')
ax.set_title("æœ€è¿‘ä¸‰ä¸ªæœˆé”€å”®é¢åŠçŽ¯æ¯”å¢žé•¿")
ax.set_ylabel("Sales")
plt.grid()
plt.legend()
plt.tight_layout()
plt.show()
```

    æ•°æ®æ—¶é—´èŒƒå›´ï¼š 2013-01-01 00:00:00 åˆ° 2015-07-31 00:00:00
    æœ€è¿‘ä¸‰ä¸ªæœˆæ•°æ®é‡ï¼š (83377, 19)
    æ¯æœˆé”€å”®é¢ï¼š
     Date
    2015-05-01    189143897
    2015-06-01    207363373
    2015-07-01    202212874
    Freq: MS, Name: Sales, dtype: int64
    


    
![png](output_6_1.png)
    


### 3. æž„å»ºå½’å› æ¨¡åž‹
- ç‰¹å¾é€‰æ‹©ï¼šå¦‚ `Promo`, `SchoolHoliday`, `StoreType`, `Assortment`, `CompetitionDistance` ç­‰
- ä½¿ç”¨ XGBoost æ‹Ÿåˆ Sales
- å€ŸåŠ© SHAP è§£é‡Šæ¨¡åž‹é¢„æµ‹å¹¶è¿›è¡Œå½’å› åˆ†æž


```python
import xgboost as xgb
import shap

# é€‰å–ç›¸å…³ç‰¹å¾
features = ['Promo', 'SchoolHoliday', 'StateHoliday', 'StoreType', 
            'Assortment', 'CompetitionDistance', 'DayOfWeek']
df_model = recent_df[features + ['Sales']].copy()

# ç¼–ç ç±»åˆ«å˜é‡
df_model = pd.get_dummies(df_model, columns=['StateHoliday', 'StoreType', 'Assortment'], drop_first=True)

# ç‰¹å¾ & ç›®æ ‡
X = df_model.drop(columns='Sales')
y = df_model['Sales']

# æ‹Ÿåˆæ¨¡åž‹
model = xgb.XGBRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# SHAP åˆ†æž
explainer = shap.Explainer(model)
shap_values = explainer(X)

# å¯è§†åŒ–ï¼šSHAP å¹³å‡å½±å“åŠ›ï¼ˆå½’å› ï¼‰
shap.plots.bar(shap_values, max_display=10)

```


    
![png](output_8_0.png)
    


ç‰¹å¾	SHAPå€¼	ä¸šåŠ¡è§£é‡Š
Promo	+1061.28	ä¿ƒé”€æ´»åŠ¨å¯¹é”€å”®é¢æå‡ä½œç”¨æœ€æ˜¾è‘—ï¼Œå¹³å‡è´¡çŒ®å€¼æœ€é«˜ï¼Œè¯´æ˜Žä¿ƒé”€ç­–ç•¥æœ‰æ•ˆæ€§æžä½³
CompetitionDistance	+894.09	ç«žäº‰åº—é“ºè·ç¦»è¶Šè¿œï¼Œé”€å”®é¢è¶Šé«˜ï¼ˆå¯èƒ½ä¸Žå‘¨è¾¹å®¢æºåž„æ–­æˆ–ç«žäº‰åŽ‹åŠ›å‡å°ç›¸å…³ï¼‰
Assortment_c	+551.71	å•†å“åˆ†ç±»cï¼ˆå¯èƒ½ä¸ºé«˜ç«¯æˆ–ç‰¹è‰²å•†å“ç»„åˆï¼‰å¯¹é”€å”®é¢æœ‰å¼ºæ­£å‘å½±å“
DayOfWeek	+407.35	å‘¨å†…æŸå‡ å¤©ï¼ˆå¦‚å‘¨æœ«ï¼‰çš„é”€å”®è¡¨çŽ°æ˜¾è‘—ä¼˜äºŽå…¶ä»–æ—¥æœŸ
StoreType_d	+208.26	åº—é“ºç±»åž‹dï¼ˆå¯èƒ½ä¸ºäº¤é€šæž¢çº½åº—æˆ–å¤§åž‹å•†åœºåº—ï¼‰çš„é”€å”®ä¼˜åŠ¿æ˜Žæ˜¾




åˆ†æžç»“æžœï¼š
1. ç«žäº‰è·ç¦»çš„æ­£å‘å½±å“

åå¸¸çŽ°è±¡ï¼šé€šå¸¸ç«žäº‰è·ç¦»è¶Šè¿‘ï¼Œé”€å”®é¢å¯èƒ½å› åˆ†æµè€Œä¸‹é™ï¼Œä½†æ­¤å¤„æ˜¾ç¤ºç«žäº‰è·ç¦»è¶Šè¿œè´¡çŒ®åº¦è¶Šã€‚

å¯å› ï¼š

æ•°æ®ä¸­ç«žäº‰è·ç¦»ç¼ºå¤±å€¼è¾ƒå¤šï¼ˆéœ€æ£€æŸ¥CompetitionDistancçš„ç¼ºå¤±çŽ‡ï¼‰

åº—é“ºé€‰å€ç­–ç•¥ç‰¹æ®Šï¼ˆå¦‚ååœ°åŒºåž„æ–­æ€§å¼ºï¼‰

ç«žäº‰åº—é“ºçš„å­˜åœ¨åè€Œå¸¦æ¥é›†èšæ•ˆåº”ï¼ˆ2. éœ€ç»“åˆä¸šåŠ¡éªŒè¯

å•†å“åˆ†ç±»çš„å·®å¼‚

Assortment_cè´¡çŒ®åº¦æ˜¾è‘—é«˜äºŽAssortment_bï¼ˆ+551.71s +2.29ï¼‰ï¼Œè¯´æ˜Žï¼šï¼Œ
å•†å“ç»„åˆcæ›´ç¬¦åˆæ¶ˆè´¹è€…
éœ€3. 

åˆ†ç±»bå¯èƒ½è¦ä¼˜åŒ–æˆ–æ·˜æ±°

åº—é“ºç±»åž‹çš„å±‚çº§æ•ˆåº”

StreTypeè´¡çŒ®åº¦æŽ’åºï¼šd > c > b

åæ˜ ä¸åŒåº—é“ºç±»åž‹çš„å¸‚åœºç«žäº‰åŠ›å·®å¼‚ï¼Œå»ºè®®ä¼˜å…ˆæ‰©å±•dç±»åº—é“º

ä¸šåŠ¡å»ºè®®ï¼š
1. ä¿ƒé”€ç­–ç•¥ä¼˜åŒ–
å¢žåŠ ä¿ƒé”€é¢‘çŽ‡ï¼Œå°¤å…¶æ˜¯å¯¹é«˜è´¡çŒ®åº—é“ºç±»åž‹ï¼ˆdç±»ï¼‰å’Œå•†å“åˆ†ç±»ï¼ˆcç±»ï¼‰
åˆ†æžä¿ƒé”€æ´»åŠ¨çš„è¾¹é™…æ”¶ç›Šï¼Œé¿å…è¿‡åº¦ä¾èµ–ä¿ƒé”€
2. ç«žäº‰è·ç¦»çš„æ·±å…¥åˆ†æž
æ£€æŸ¥CompetitionDistanceæ•°æ®è´¨é‡ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ï¼‰
ç»“åˆåœ°ç†ä¿¡æ¯æ•°æ®ï¼Œç ”ç©¶ç«žäº‰åº—é“ºåˆ†å¸ƒä¸Žé”€å”®é¢çš„å…³ç³»
3. å•†å“ç»„åˆè°ƒæ•´
æ‰©å¤§Assortment_cçš„å•†å“è¦†ç›–èŒƒå›´
è¯„ä¼°Assortment_bçš„ç•™å­˜å¿…è¦æ€§
4. åº—é“ºç±»åž‹ä¼˜å…ˆçº§
èµ„æºå‘StoreType_då€¾æ–œï¼ˆå¦‚é€‰å€ã€åº“å­˜ã€è¥é”€ï¼‰
åˆ†æžStoreType_cä¸Žbçš„è¿è¥å·®å¼‚ï¼Œåˆ¶å®šæ”¹è¿›æ–¹æ¡ˆ


```python
# åˆ†ç»„æŸ¥çœ‹å˜é‡å¹³å‡å€¼æŒ‰æœˆä»½å¯¹æ¯”
recent_df['Month'] = recent_df['Date'].dt.to_period("M").astype(str)
summary_table = recent_df.groupby('Month')[['Promo', 'SchoolHoliday', 'CompetitionDistance']].mean()
print(summary_table)
```

                Promo  SchoolHoliday  CompetitionDistance
    Month                                                
    2015-05  0.431354       0.085011          5470.693917
    2015-06  0.446505       0.055835          5463.992098
    2015-07  0.459433       0.405813          5435.897507
    

    
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    

aiåˆ†æž
æç¤ºè¯ï¼šåˆ†æžç»“æžœã€å¯¹æ¯ä¸ªæ•°æ®è¿›è¡Œåˆ†æžæŽ¢è®¨
âœ… Promo åˆ—ï¼ˆä¿ƒé”€æ´»åŠ¨ï¼‰
è¡¨ç¤ºè¯¥æœˆå‚ä¸Žä¿ƒé”€çš„é—¨åº—å æ¯”ï¼š

5æœˆï¼š43.1% çš„é—¨åº—æœ‰ä¿ƒé”€

6æœˆï¼š44.7%

7æœˆï¼š45.9%

è¶‹åŠ¿ï¼šç•¥å¾®ä¸Šå‡ï¼Œå¯èƒ½å¸¦æ¥é”€å”®å¢žé•¿ã€‚
âœ… SchoolHoliday åˆ—ï¼ˆå­¦æ ¡å‡æœŸï¼‰
è¡¨ç¤ºè¯¥æœˆæœ‰å­¦æ ¡å‡æœŸçš„å¤©æ•°æ¯”ä¾‹æˆ–é—¨åº—å æ¯”ï¼š

5æœˆï¼šä»… 8.5%

6æœˆï¼š5.6%

7æœˆï¼š40.6%

è¶‹åŠ¿ï¼š7æœˆå¤§å¹…ä¸Šå‡ï¼Œè¯´æ˜Ž7æœˆè¿›å…¥æš‘å‡ï¼Œå®¶åº­å‡ºè¡Œ/è´­ç‰©å¯èƒ½å¢žåŠ ï¼Œå¯¹é”€å”®æ˜¯ä¸€ä¸ªç§¯æžå½±å“ã€‚
âœ… CompetitionDistance åˆ—ï¼ˆç«žäº‰å¯¹æ‰‹è·ç¦»ï¼‰
æ•°å€¼è¶Šé«˜è¯´æ˜Žç«žäº‰å¯¹æ‰‹è¶Šè¿œï¼Œç†è®ºä¸Šå¯¹è‡ªå·±è¶Šæœ‰åˆ©ã€‚

ç¨æœ‰ä¸‹é™ï¼Œä»Ž 5470 ç±³é™åˆ° 5436 ç±³ï¼Œå½±å“ä¸å¤§ï¼Œå˜åŒ–å¹…åº¦å¾ˆå°ã€‚
7æœˆé”€å”®é¢å¢žåŠ ï¼ˆå‡è®¾ä½ ä¹‹å‰å›¾é‡Œçœ‹åˆ°çš„ç¡®æ˜¯å¢žåŠ ï¼‰ï¼Œå¯èƒ½ç”±ä»¥ä¸‹å‡ æ–¹é¢æŽ¨åŠ¨ï¼š

âœ… ä¿ƒé”€æ´»åŠ¨ç•¥å¢žåŠ ï¼ˆä¿ƒé”€é—¨åº—ä»Ž 43.1% â†’ 45.9%ï¼‰

âœ… æš‘å‡æ¥ä¸´ï¼ŒSchoolHoliday å æ¯”æš´å¢žè‡³ 40%+

âš ï¸ ç«žäº‰çŽ¯å¢ƒå˜åŒ–ä¸æ˜¾è‘—ï¼ˆå¯ä»¥æš‚æ—¶å¿½ç•¥ï¼‰



```python
import seaborn as sns
import matplotlib.pyplot as plt

# é€‰å– 7~9 æœˆæ•°æ®
recent_df = df[(df['Date'] >= '2015-07-01') & (df['Date'] <= '2015-09-30')]

# é€‰å–ç”¨äºŽå½’å› åˆ†æžçš„å­—æ®µ
corr_df = recent_df[['Sales', 'Promo', 'SchoolHoliday', 'CompetitionDistance', 'Customers']]

# è®¡ç®—ç›¸å…³ç³»æ•°
corr = corr_df.corr()

# å¯è§†åŒ–
plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm')
plt.title("æœ€è¿‘ä¸‰ä¸ªæœˆé”€å”®ç›¸å…³æ€§çƒ­åŠ›å›¾")
plt.tight_layout()
plt.show()
```


    
![png](output_13_0.png)
    


ä¸Šè¿°ç›¸å…³çƒ­åŠ›å›¾æ¥çœ‹ï¼Œè¿‘ä¸‰ä¸ªæœˆCustomersæ•°é‡å¯¹é”€å”®é¢çš„å½±å“æ˜¯æœ€å¤§è¾¾åˆ°ï¼Œå…¶æ¬¡æ˜¯ä¿ƒé”€æ´»åŠ¨ã€‚å­¦æ ¡å‡æœŸï¼Œç«žäº‰å¯¹æ‰‹è·ç¦»çš„å½±å“å‡ ä¹Žå¯ä»¥å¿½ç•¥ä¸è®°ï¼Œ
è¯´æ˜Žåº”è¯¥ä»Žé¡¾å®¢æ•°é‡å’Œä¿ƒé”€æ´»åŠ¨åŽ»è¿›è¡Œç­–åˆ’ï¼Œä»¥å¢žåŠ é”€å”®é¢


```python
import xgboost as xgb
import shap

# ç‰¹å¾å·¥ç¨‹
features = ['Promo', 'SchoolHoliday', 'CompetitionDistance', 'Customers']
X = recent_df[features]
y = recent_df['Sales']

# è®­ç»ƒ XGBoost æ¨¡åž‹
model = xgb.XGBRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# ä½¿ç”¨ SHAP è¿›è¡Œå½’å› åˆ†æž
explainer = shap.Explainer(model)
shap_values = explainer(X)

# å¯è§†åŒ–é‡è¦æ€§
shap.summary_plot(shap_values, X, plot_type="bar")

```


    
![png](output_15_0.png)
    


ä»Žå½’å› åˆ†æžç»“æžœæ¥çœ‹ï¼Œè¿‘ä¸‰ä¸ªæœˆé¡¾å®¢æ•°é‡å¯¹é”€å”®é¢çš„å½±å“æ˜¯æœ€å¤§çš„ï¼Œå…¶æ¬¡æ˜¯ç«žäº‰å¯¹æ‰‹è·ç¦»ï¼Œè¯´æ˜Žä»Žç®€å•çš„ç›¸å…³åˆ†æžæ¥çœ‹ä¼šå¿½ç•¥ä¸€äº›ä¿¡æ¯ï¼Œå­¦æ ¡å‡æœŸå¯¹æ¨¡åž‹çš„å½±å“å¯ä»¥å¿½ç•¥ä¸è®°
æ€»ä¹‹ï¼Œåº”è¯¥é‡è§†Customersæ•°é‡ï¼Œæ”¹å–„ä¿ƒé”€æ´»åŠ¨æ‰‹æ®µã€‚
